// AI Prompt Template for strict JSON-only feedback

// CHANGED: Shortened from 60+ characters to ~40 characters
// Saves ~5-10 tokens per request
export const SYSTEM_MESSAGE = "æ—¥æœ¬ã®ä¸­å­¦ç”Ÿå‘ã‘è‹±ä½œæ–‡ãƒã‚§ãƒƒã‚«ãƒ¼ã€‚JSONå½¢å¼ã§å›ç­”ã€‚æ–‡æ³•çš„ã«æ­£ã—ã„è‹±æ–‡ã¯çµ¶å¯¾ã«é–“é•ã„ã¨ã—ãªã„ã€‚æ–‡æ³•ã‚¨ãƒ©ãƒ¼ã¨ç¶´ã‚ŠãƒŸã‚¹ã®ã¿è¨‚æ­£ã€‚";

// CHANGED: Balanced prompt - educational but not too verbose
// Emphasizes clear explanations with grammar rules
export function buildCheckPrompt(text) {
  // NEW: Limit input to 500 characters to prevent huge prompts
  const limitedText = text.slice(0, 500);
  
  // Optional: Log if text was truncated
  if (text.length > 500) {
    console.warn(`Input truncated: ${text.length} â†’ 500 characters`);
  }
  
  return `ç”Ÿå¾’ã®è‹±æ–‡: "${limitedText}"

å‡ºåŠ›ä»•æ§˜ï¼ˆJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã€ä»–ã®æ–‡å­—ãƒ»ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ä¸å¯ï¼‰:
- keys: mistakes(array), overallScore(number: 0-100), levelUp(string)
- mistakes[].type ã¯ "grammar" | "vocabulary" | "spelling" ã®ã„ãšã‚Œã‹
- ãƒŸã‚¹ãŒãªã‘ã‚Œã° mistakes ã¯ [] ã«ã™ã‚‹

å‡ºåŠ›ä¾‹ï¼ˆå€¤ã¯ä¾‹ã€‚å¿…ãšæœ‰åŠ¹ãªJSONã§è¿”ã™ï¼‰:
{
  "mistakes": [
    {
      "original": "I go to school yesterday.",
      "corrected": "I went to school yesterday.",
      "explanation": "éå»ã®å‡ºæ¥äº‹ãªã®ã§å‹•è©ã¯éå»å½¢ã«ã—ã¾ã™ã€‚",
      "type": "grammar"
    }
  ],
  "overallScore": 85,
  "levelUp": "æ™‚åˆ¶ã®ä¸€è‡´ã‚’å¾©ç¿’ã—ã¾ã—ã‚‡ã†ã€‚çŸ­ã„è‹±æ–‡ã§ã‚‚ä¸»èªã¨å‹•è©ã®å½¢ã‚’æ„è­˜ã™ã‚‹ã¨ã•ã‚‰ã«è‰¯ããªã‚Šã¾ã™ã€‚"
}

å³å®ˆãƒ«ãƒ¼ãƒ«:
1. æ–‡æ³•çš„ã«æ­£ã—ã„è‹±æ–‡ã¯é–“é•ã„ã¨ã—ã¦å‡ºåŠ›ã—ãªã„
2. æŒ‡æ‘˜ã¯æ–‡æ³•ã‚¨ãƒ©ãƒ¼ã¨ç¶´ã‚ŠãƒŸã‚¹ã®ã¿
3. å†…å®¹ã®è¿½åŠ ãƒ»å¤‰æ›´ã€èªå½™ã®è¨€ã„æ›ãˆã€ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾ææ¡ˆã¯ mistakes ã«å«ã‚ãªã„ï¼ˆlevelUp ã«è¨˜è¼‰ï¼‰

æ³¨æ„:
- JSONä»¥å¤–ã®æ–‡å­—åˆ—ã‚„ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã¯å‡ºåŠ›ã—ãªã„
- å€¤ã¯æ—¥æœ¬èªã§æ§‹ã„ã¾ã›ã‚“ãŒã€ã‚­ãƒ¼åã¯å¿…ãšä¸Šè¨˜è‹±èªã®ã¾ã¾
`;
}

export const GROQ_SETTINGS = {
  model: "llama-3.3-70b-versatile",
  // CHANGED: Reduced from 0.5 to 0.3
  // Lower temperature = more consistent, focused responses
  temperature: 0.2,
  // CHANGED: Increased to 1200 to allow for educational explanations
  // Still prevents extreme spikes but allows detailed grammar explanations
  // Typical response: 400-800 tokens
  max_tokens: 600,
  response_format: { type: "json_object" }
};

// NEW: Helper function to log token usage
// Use this in your API call to monitor usage patterns
export function logTokenUsage(response, inputText) {
  const usage = response.usage;
  console.log('ğŸ“Š Token Usage:', {
    prompt: usage.prompt_tokens,
    completion: usage.completion_tokens,
    total: usage.total_tokens,
    inputLength: inputText.length,
    efficiency: `${(usage.total_tokens / inputText.length).toFixed(2)} tokens/char`
  });
}
