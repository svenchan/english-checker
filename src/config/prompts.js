// AI Prompt Template for strict JSON-only feedback

// CHANGED: Shortened from 60+ characters to ~40 characters
// Saves ~5-10 tokens per request
export const SYSTEM_MESSAGE = "æ—¥æœ¬ã®ä¸­å­¦ç”Ÿå‘ã‘è‹±ä½œæ–‡ãƒã‚§ãƒƒã‚«ãƒ¼ã€‚JSONå½¢å¼ã§å›ç­”ã€‚æ–‡æ³•çš„ã«æ­£ã—ã„è‹±æ–‡ã¯çµ¶å¯¾ã«é–“é•ã„ã¨ã—ãªã„ã€‚æ–‡æ³•ã‚¨ãƒ©ãƒ¼ã¨ç¶´ã‚ŠãƒŸã‚¹ã®ã¿è¨‚æ­£ã€‚";

// CHANGED: Balanced prompt - educational but not too verbose
// Emphasizes clear explanations with grammar rules
export function buildCheckPrompt(text, topicText = null) {
  // NEW: Limit input to 500 characters to prevent huge prompts
  const limitedText = text.slice(0, 500);
  
  // Optional: Log if text was truncated
  if (text.length > 500) {
    console.warn(`Input truncated: ${text.length} â†’ 500 characters`);
  }

  const topicSection = topicText
    ? `æŒ‡å®šãƒˆãƒ”ãƒƒã‚¯: "${topicText}"
- ãƒ†ãƒ¼ãƒã‹ã‚‰é€¸ã‚ŒãŸç®‡æ‰€ã¯PREPãƒã‚§ãƒƒã‚¯å†…ã§å¿…ãšæŒ‡æ‘˜ã™ã‚‹ã“ã¨ã€‚

`
    : "";
  
  return `${topicSection}ç”Ÿå¾’ã®è‹±æ–‡: "${limitedText}"

å‡ºåŠ›ä»•æ§˜ï¼ˆJSONã®ã¿ã€ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ä¸å¯ï¼‰:
- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {"mistakes":[...],"overallScore":0-100,"topicFeedback":{...}}
- mistakes[].type âˆˆ {"grammar","vocabulary","spelling"}ã€‚èª¤ã‚ŠãŒç„¡ã‘ã‚Œã° []ã€‚
- topicFeedback = {
    "onTopicSummary": "ãƒ†ãƒ¼ãƒé©åˆã‚’1-2æ–‡ã§è¦ç´„ï¼ˆãƒ†ãƒ¼ãƒãŒç„¡ã‘ã‚Œã°æ˜è¨˜ï¼‰",
    "prepChecklist": {
      "point": {...},
      "reason": {...},
      "evidence": {...},
      "pointSummary": {...}
    },
    "improvementTips": "PREPè¦–ç‚¹ã®è¿½åŠ åŠ©è¨€"
  }
- prepChecklist å„é …ç›®ã¯ { "met": true/false, "note": "çŸ­ã„è£œè¶³" } å½¢å¼ã€‚
- PREPï¼ˆPointâ†’Reasonâ†’Evidenceâ†’Pointï¼‰é †ã‚’å®ˆã‚Œã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹

å‡ºåŠ›ä¾‹ï¼ˆè¦ç´„å½¢ã§OKã€å¿…ãšæœ‰åŠ¹ãªJSONï¼‰:
{"mistakes":[{"original":"I go to school yesterday.","corrected":"I went to school yesterday.","explanation":"éå»ãªã®ã§éå»å½¢ã€‚","type":"grammar"}],"overallScore":85,"topicFeedback":{"onTopicSummary":"ãƒ†ãƒ¼ãƒã«æ²¿ã£ã¦æ˜ç¢ºã€‚","prepChecklist":{"point":{"met":true,"note":"ä¸»å¼µã‚ã‚Š"},"reason":{"met":true,"note":"ç†ç”±æç¤º"},"evidence":{"met":false,"note":"å…·ä½“ä¾‹ä¸è¶³"},"pointSummary":{"met":true,"note":"ã¾ã¨ã‚ã‚ã‚Š"}},"improvementTips":"ç†ç”±å¾Œã«å…·ä½“ä¾‹ã‚’è¿½åŠ ã€‚"}}

å¿…é ˆãƒ«ãƒ¼ãƒ«:
- æ–‡æ³•çš„ã«æ­£ã—ã„è‹±æ–‡ã¯èª¤ã‚Šã«ã—ãªã„ã€‚æŒ‡æ‘˜ã¯æ–‡æ³•/ç¶´ã‚Šã®ã¿ã§èªå½™ææ¡ˆã¯é™¤å¤–ã€‚
- JSONä»¥å¤–ã‚’å‡ºåŠ›ã—ãªã„ã€‚ã‚­ãƒ¼åã¯è‹±èªã®ã¾ã¾ã€å€¤ã¯æ—¥æœ¬èªã§å¯ã€‚
`;
}

export const GROQ_SETTINGS = {
  model: "llama-3.3-70b-versatile",
  // CHANGED: Reduced from 0.5 to 0.3
  // Lower temperature = more consistent, focused responses
  temperature: 0.2,
  // CHANGED: Increased to 1200 to allow for educational explanations
  // Still prevents extreme spikes but allows detailed grammar explanations
  // Typical response: 400-800 tokens
  max_tokens: 600,
  response_format: { type: "json_object" }
};

// NEW: Helper function to log token usage
// Use this in your API call to monitor usage patterns
export function logTokenUsage(response, inputText) {
  const usage = response.usage;
  console.log('ğŸ“Š Token Usage:', {
    prompt: usage.prompt_tokens,
    completion: usage.completion_tokens,
    total: usage.total_tokens,
    inputLength: inputText.length,
    efficiency: `${(usage.total_tokens / inputText.length).toFixed(2)} tokens/char`
  });
}
