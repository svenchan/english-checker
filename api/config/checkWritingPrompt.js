
// * AI Prompt Templates - Optimized Version


// CHANGED: Shortened from 60+ characters to ~40 characters
// Saves ~5-10 tokens per request
const SYSTEM_MESSAGE = "æ—¥æœ¬ã®ä¸­å­¦ç”Ÿå‘ã‘è‹±ä½œæ–‡ãƒã‚§ãƒƒã‚«ãƒ¼ã€‚JSONå½¢å¼ã§å›ç­”ã€‚æ–‡æ³•çš„ã«æ­£ã—ã„è‹±æ–‡ã¯çµ¶å¯¾ã«é–“é•ã„ã¨ã—ãªã„ã€‚æ–‡æ³•ã‚¨ãƒ©ãƒ¼ã¨ç¶´ã‚ŠãƒŸã‚¹ã®ã¿è¨‚æ­£ã€‚æ—¥æœ¬èªã®ã¿ã§å›ç­”ã€‚";

// CHANGED: Balanced prompt - educational but not too verbose
// Emphasizes clear explanations with grammar rules
function buildCheckPrompt(text) {
  // NEW: Limit input to 500 characters to prevent huge prompts
  const limitedText = text.slice(0, 500);
  
  // Optional: Log if text was truncated
  if (text.length > 500) {
    console.warn(`Input truncated: ${text.length} â†’ 500 characters`);
  }
  
  return `ç”Ÿå¾’ã®è‹±æ–‡: "${limitedText}"

ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "mistakes": [
    {
      "original": "é–“é•ã£ãŸéƒ¨åˆ†",
      "corrected": "æ­£ã—ã„è‹±èª",
      "explanation": "ãªãœé–“é•ã„ã‹ã€ã©ã®æ–‡æ³•ãƒ«ãƒ¼ãƒ«ã«é–¢ä¿‚ã™ã‚‹ã‹ï¼ˆä¾‹ï¼šè‹±èªã¯ä¸»èª+å‹•è©ã®é †ç•ªã€beå‹•è©ãŒå¿…è¦ã€ãªã©ï¼‰ã‚’1ã€œ2æ–‡ã§èª¬æ˜",
      "type": "grammar|vocabulary|spelling"
    }
  ],
  "overallScore": 0-100,
  "levelUp": "ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾ã¨å†…å®¹ã®è¿½åŠ ã‚„å¤‰æ›´ã®ææ¡ˆã®ã‚³ãƒ¡ãƒ³ãƒˆ"
}

ã€çµ¶å¯¾ã«å®ˆã‚‹ãƒ«ãƒ¼ãƒ«ã€‘
1. æ–‡æ³•çš„ã«æ­£ã—ã„è‹±æ–‡ã¯çµ¶å¯¾ã«é–“é•ã„ã¨ã—ãªã„
2. ç¶´ã‚ŠãƒŸã‚¹ã¨æ˜ç¢ºãªæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã®ã¿ã‚’æŒ‡æ‘˜
3. èªå½™ã®ç½®ãæ›ãˆã¯çµ¶å¯¾ã«ã—ãªã„ï¼ˆä¾‹ï¼šã€Œgoodã€â†’ã€Œexcellentã€ã¯ç¦æ­¢ï¼‰
4. ã‚¹ã‚¿ã‚¤ãƒ«ã‚„è¨€ã„å›ã—ã®æ”¹å–„ã¯çµ¶å¯¾ã«ã—ãªã„

explanationã§ã¯æ–‡æ³•ãƒ«ãƒ¼ãƒ«ã‚’æ˜ç¢ºã«èª¬æ˜ï¼ˆä¾‹ï¼šã€Œè‹±èªã¯ä¸»èª+å‹•è©ã®æ§‹é€ ã€ã€Œbeå‹•è©ãŒå¿…è¦ã€ãªã©ï¼‰
level upã§ã¯ã€ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾ã‚„æƒ…å ±ã®ä»˜ã‘åŠ ãˆã®ä¾‹ã‚’ææ¡ˆã™ã‚‹ãŒã€ææ¡ˆã¯å¿…ãšé›£ã—ã„å˜èªä½¿ã‚ãªã„ã€‚
å®Œç’§ãªè‹±æ–‡ã¯mistakesç©ºé…åˆ—ã€100ç‚¹

JSONã®ã¿è¿”ã—ã¦ãã ã•ã„ã€‚`;
}

const GROQ_SETTINGS = {
  model: "llama-3.3-70b-versatile",
  // CHANGED: Reduced from 0.5 to 0.3
  // Lower temperature = more consistent, focused responses
  temperature: 0.2,
  // CHANGED: Increased to 1200 to allow for educational explanations
  // Still prevents extreme spikes but allows detailed grammar explanations
  // Typical response: 400-800 tokens
  max_tokens: 600,
  response_format: { type: "json_object" }
};

// NEW: Helper function to log token usage
// Use this in your API call to monitor usage patterns
function logTokenUsage(response, inputText) {
  const usage = response.usage;
  console.log('ğŸ“Š Token Usage:', {
    prompt: usage.prompt_tokens,
    completion: usage.completion_tokens,
    total: usage.total_tokens,
    inputLength: inputText.length,
    efficiency: `${(usage.total_tokens / inputText.length).toFixed(2)} tokens/char`
  });
}


module.exports = {
  SYSTEM_MESSAGE,
  buildCheckPrompt,
  GROQ_SETTINGS,
  logTokenUsage  // NEW: Export the logging helper
};
